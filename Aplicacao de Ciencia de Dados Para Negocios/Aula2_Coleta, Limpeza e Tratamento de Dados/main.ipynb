{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prática Integradora em Ciência de Dados para Negócios - Atividade 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando coleta de dados de livros...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando páginas: 100%|██████████| 3/3 [00:06<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dados salvos com sucesso em dados_livros.csv\n",
      "Total de produtos coletados: 60\n",
      "\n",
      "Primeiros registros:\n",
      "                                  Título   Preço Disponibilidade  \\\n",
      "0                   A Light in the Attic  £51.77        In stock   \n",
      "1                     Tipping the Velvet  £53.74        In stock   \n",
      "2                             Soumission  £50.10        In stock   \n",
      "3                          Sharp Objects  £47.82        In stock   \n",
      "4  Sapiens: A Brief History of Humankind  £54.23        In stock   \n",
      "\n",
      "        Avaliação  \n",
      "0  Three estrelas  \n",
      "1    One estrelas  \n",
      "2    One estrelas  \n",
      "3   Four estrelas  \n",
      "4   Five estrelas  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "def configurar_headers():\n",
    "    \"\"\"Configura headers para evitar bloqueios\"\"\"\n",
    "    return {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "        'Accept-Encoding': 'gzip, deflate',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "        'Referer': 'https://www.google.com/'\n",
    "    }\n",
    "\n",
    "def extrair_dados_produto(produto):\n",
    "    \"\"\"Extrai dados de um único produto\"\"\"\n",
    "    try:\n",
    "        titulo = produto.h3.a['title']\n",
    "        preco = produto.find('p', class_='price_color').get_text()\n",
    "        disponibilidade = produto.find('p', class_='instock').get_text().strip()\n",
    "        avaliacao = produto.find('p', class_='star-rating')['class'][1]\n",
    "        \n",
    "        return {\n",
    "            'Título': titulo,\n",
    "            'Preço': preco,\n",
    "            'Disponibilidade': disponibilidade,\n",
    "            'Avaliação': f\"{avaliacao} estrelas\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao extrair produto: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def scrape_pagina(url, headers):\n",
    "    \"\"\"Faz scraping de uma página individual\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        response.encoding = 'utf-8'  # Força a codificação UTF-8\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        produtos = soup.find_all('article', class_='product_pod')\n",
    "        \n",
    "        dados_pagina = []\n",
    "        for produto in produtos:\n",
    "            dados = extrair_dados_produto(produto)\n",
    "            if dados:\n",
    "                dados_pagina.append(dados)\n",
    "        \n",
    "        return dados_pagina\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erro na requisição para {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_todas_paginas(base_url, max_paginas=3):\n",
    "    \"\"\"Faz scraping de múltiplas páginas\"\"\"\n",
    "    headers = configurar_headers()\n",
    "    todos_dados = []\n",
    "    \n",
    "    with tqdm(total=max_paginas, desc=\"Processando páginas\") as pbar:\n",
    "        for pagina in range(1, max_paginas + 1):\n",
    "            if pagina == 1:\n",
    "                url = base_url\n",
    "            else:\n",
    "                url = f\"{base_url}/catalogue/page-{pagina}.html\"\n",
    "            \n",
    "            dados_pagina = scrape_pagina(url, headers)\n",
    "            if dados_pagina:\n",
    "                todos_dados.extend(dados_pagina)\n",
    "            pbar.update(1)\n",
    "            time.sleep(1.5)  # Delay maior para evitar bloqueio\n",
    "            \n",
    "    return todos_dados\n",
    "\n",
    "def salvar_dados(dados):\n",
    "    \"\"\"Salva os dados em CSV\"\"\"\n",
    "    if not dados:\n",
    "        print(\"Nenhum dado foi coletado. Verifique:\")\n",
    "        print(\"- Sua conexão com a internet\")\n",
    "        print(\"- Se o site está acessível (http://books.toscrape.com)\")\n",
    "        print(\"- Se os seletores CSS ainda são válidos\")\n",
    "        return\n",
    "    \n",
    "    df = pd.DataFrame(dados)\n",
    "    df.to_csv('dados_livros.csv', index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nDados salvos com sucesso em dados_livros.csv\")\n",
    "    print(f\"Total de produtos coletados: {len(df)}\")\n",
    "    print(\"\\nPrimeiros registros:\")\n",
    "    print(df.head())\n",
    "\n",
    "def main():\n",
    "    \"\"\"Função principal\"\"\"\n",
    "    print(\"Iniciando coleta de dados de livros...\\n\")\n",
    "    base_url = \"http://books.toscrape.com\"\n",
    "    \n",
    "    # Teste de conexão com o site\n",
    "    try:\n",
    "        test_response = requests.get(base_url, timeout=10)\n",
    "        test_response.raise_for_status()\n",
    "    except:\n",
    "        print(\"Erro: Não foi possível acessar o site. Verifique sua conexão com a internet.\")\n",
    "        return\n",
    "    \n",
    "    dados_livros = scrape_todas_paginas(base_url)\n",
    "    salvar_dados(dados_livros)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2: Limpeza de Dados (simulando OpenRefine em Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dados carregados. Total: 60 registros\n",
      "Registros após remover duplicatas: 60\n",
      "\n",
      "Iniciando tratamento de avaliações...\n",
      "\n",
      "Exemplo de avaliações brutas:\n",
      "0    Three estrelas\n",
      "1      One estrelas\n",
      "2      One estrelas\n",
      "3     Four estrelas\n",
      "4     Five estrelas\n",
      "5      One estrelas\n",
      "6     Four estrelas\n",
      "7    Three estrelas\n",
      "8     Four estrelas\n",
      "9      One estrelas\n",
      "Name: Avaliação, dtype: object\n",
      "\n",
      "Distribuição das avaliações corrigidas:\n",
      "Avaliação_Categoria\n",
      "Bom          23\n",
      "Ruim         23\n",
      "Excelente    14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== RESULTADOS FINAIS ===\n",
      "\n",
      "Distribuição de avaliações:\n",
      "Avaliação_Categoria\n",
      "Bom          23\n",
      "Ruim         23\n",
      "Excelente    14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribuição de preços:\n",
      "Categoria_Preço\n",
      "Muito Caro    35\n",
      "Caro          22\n",
      "Médio          3\n",
      "Barato         0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Amostra dos dados finais:\n",
      "                                  Título  Preço_BRL Avaliação_Categoria  \\\n",
      "0                   A Light in the Attic    336.505                 Bom   \n",
      "1                     Tipping the Velvet    349.310                Ruim   \n",
      "2                             Soumission    325.650                Ruim   \n",
      "3                          Sharp Objects    310.830                 Bom   \n",
      "4  Sapiens: A Brief History of Humankind    352.495           Excelente   \n",
      "\n",
      "  Disponibilidade  \n",
      "0      Disponível  \n",
      "1      Disponível  \n",
      "2      Disponível  \n",
      "3      Disponível  \n",
      "4      Disponível  \n"
     ]
    }
   ],
   "source": [
    "def tratar_avaliacoes_corretamente(df):\n",
    "    \"\"\"Função corrigida para extrair avaliações em português/inglês\"\"\"\n",
    "    print(\"\\nIniciando tratamento de avaliações...\")\n",
    "    \n",
    "    # Mostrar amostra dos dados brutos\n",
    "    print(\"\\nExemplo de avaliações brutas:\")\n",
    "    print(df['Avaliação'].head(10))\n",
    "    \n",
    "    # Criar dicionário de mapeamento para português e inglês\n",
    "    rating_map = {\n",
    "        'one': 1, 'um': 1, 'uma': 1,\n",
    "        'two': 2, 'dois': 2, 'duas': 2,\n",
    "        'three': 3, 'três': 3,\n",
    "        'four': 4, 'quatro': 4,\n",
    "        'five': 5, 'cinco': 5\n",
    "    }\n",
    "    \n",
    "    # Processar cada avaliação\n",
    "    avaliacoes_numericas = []\n",
    "    for avaliacao in df['Avaliação']:\n",
    "        # Converter para minúsculas e remover 'estrelas'\n",
    "        avaliacao = str(avaliacao).lower().replace('estrelas', '').strip()\n",
    "        \n",
    "        # Procurar por correspondência no dicionário\n",
    "        encontrou = False\n",
    "        for termo, valor in rating_map.items():\n",
    "            if termo in avaliacao:\n",
    "                avaliacoes_numericas.append(valor)\n",
    "                encontrou = True\n",
    "                break\n",
    "        \n",
    "        if not encontrou:\n",
    "            avaliacoes_numericas.append(0)  # Padrão para não avaliado\n",
    "    \n",
    "    df['Avaliação_Numérica'] = avaliacoes_numericas\n",
    "    \n",
    "    # Criar categorias\n",
    "    conditions = [\n",
    "        (df['Avaliação_Numérica'] == 0),\n",
    "        (df['Avaliação_Numérica'] <= 2),\n",
    "        (df['Avaliação_Numérica'] <= 4),\n",
    "        (df['Avaliação_Numérica'] == 5)\n",
    "    ]\n",
    "    choices = ['Não avaliado', 'Ruim', 'Bom', 'Excelente']\n",
    "    \n",
    "    df['Avaliação_Categoria'] = np.select(conditions, choices, default='Não avaliado')\n",
    "    \n",
    "    print(\"\\nDistribuição das avaliações corrigidas:\")\n",
    "    print(df['Avaliação_Categoria'].value_counts())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def tratamento_final_dados():\n",
    "    \"\"\"Função completa e corrigida de tratamento de dados\"\"\"\n",
    "    try:\n",
    "        # 1. Carregar dados\n",
    "        df = pd.read_csv('dados_livros.csv', encoding='utf-8-sig')\n",
    "        print(f\"\\nDados carregados. Total: {len(df)} registros\")\n",
    "        \n",
    "        # 2. Remover duplicatas\n",
    "        df.drop_duplicates(subset=['Título'], keep='first', inplace=True)\n",
    "        print(f\"Registros após remover duplicatas: {len(df)}\")\n",
    "        \n",
    "        # 3. Tratar preços\n",
    "        df['Preço'] = df['Preço'].str.replace('£', '').astype(float)\n",
    "        df['Preço_BRL'] = df['Preço'] * 6.5\n",
    "        \n",
    "        # 4. Tratar avaliações (usando a função corrigida)\n",
    "        df = tratar_avaliacoes_corretamente(df)\n",
    "        \n",
    "        # 5. Tratar disponibilidade\n",
    "        df['Disponibilidade'] = df['Disponibilidade'].apply(\n",
    "            lambda x: 'Disponível' if 'In stock' in str(x) else 'Indisponível'\n",
    "        )\n",
    "        \n",
    "        # 6. Categorizar preços\n",
    "        df['Categoria_Preço'] = pd.cut(\n",
    "            df['Preço_BRL'],\n",
    "            bins=[0, 50, 100, 200, float('inf')],\n",
    "            labels=['Barato', 'Médio', 'Caro', 'Muito Caro']\n",
    "        )\n",
    "        \n",
    "        # 7. Salvar dados tratados\n",
    "        df.to_csv('dados_livros_tratados.csv', index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        # Relatório final\n",
    "        print(\"\\n=== RESULTADOS FINAIS ===\")\n",
    "        print(\"\\nDistribuição de avaliações:\")\n",
    "        print(df['Avaliação_Categoria'].value_counts())\n",
    "        print(\"\\nDistribuição de preços:\")\n",
    "        print(df['Categoria_Preço'].value_counts())\n",
    "        print(\"\\nAmostra dos dados finais:\")\n",
    "        print(df[['Título', 'Preço_BRL', 'Avaliação_Categoria', 'Disponibilidade']].head())\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nERRO: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Executar o tratamento completo\n",
    "if __name__ == \"__main__\":\n",
    "    dados_finais = tratamento_final_dados()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3: Tratamento de Dados com Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificação inicial dos dados:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60 entries, 0 to 59\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Título               60 non-null     object \n",
      " 1   Preço                60 non-null     float64\n",
      " 2   Disponibilidade      60 non-null     object \n",
      " 3   Avaliação            60 non-null     object \n",
      " 4   Preço_BRL            60 non-null     float64\n",
      " 5   Avaliação_Numérica   60 non-null     int64  \n",
      " 6   Avaliação_Categoria  60 non-null     object \n",
      " 7   Categoria_Preço      60 non-null     object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 3.9+ KB\n",
      "None\n",
      "\n",
      "Total de livros válidos para análise: 60\n",
      "\n",
      "=== Estatísticas Finais ===\n",
      "Média de Preço (R$): 35.0\n",
      "Mediana de Preço (R$): 33.48\n",
      "Média de Avaliação (1-5): 3.0\n",
      "Livros por Categoria de Preço: {'Muito Caro': 35, 'Caro': 22, 'Médio': 3}\n",
      "Livros por Nível de Avaliação: {'Bom': 23, 'Ruim': 23, 'Excelente': 14}\n",
      "\n",
      "Distribuição Cruzada (Preço x Avaliação):\n",
      "Avaliação_Categoria  Bom  Excelente  Ruim  All\n",
      "Categoria_Preço                               \n",
      "Caro                   7          7     8   22\n",
      "Muito Caro            15          7    13   35\n",
      "Médio                  1          0     2    3\n",
      "All                   23         14    23   60\n",
      "\n",
      "Amostra dos Dados Finais:\n",
      "                                               Título  Preço Disponibilidade  \\\n",
      "22  Foolproof Preserving: A Guide to Small Batch J...  30.52      Disponível   \n",
      "23                         Chase Me (Paris Nights #2)  25.27      Disponível   \n",
      "4               Sapiens: A Brief History of Humankind  54.23      Disponível   \n",
      "21                                    How Music Works  37.32      Disponível   \n",
      "54                                             Thirst  17.27      Disponível   \n",
      "\n",
      "         Avaliação  Preço_BRL  Avaliação_Numérica Avaliação_Categoria  \\\n",
      "22  Three estrelas    198.380                   3                 Bom   \n",
      "23   Five estrelas    164.255                   5           Excelente   \n",
      "4    Five estrelas    352.495                   5           Excelente   \n",
      "21    Two estrelas    242.580                   2                Ruim   \n",
      "54   Five estrelas    112.255                   5           Excelente   \n",
      "\n",
      "   Categoria_Preço  \n",
      "22            Caro  \n",
      "23            Caro  \n",
      "4       Muito Caro  \n",
      "21      Muito Caro  \n",
      "54            Caro  \n"
     ]
    }
   ],
   "source": [
    "# --- Carregar os dados já limpos (saída da Parte 2) ---\n",
    "df = pd.read_csv('dados_livros_tratados.csv', encoding='utf-8')\n",
    "\n",
    "# --- 1. Verificação e ajuste final dos dados ---\n",
    "print(\"\\nVerificação inicial dos dados:\")\n",
    "print(df.info())\n",
    "\n",
    "# Garantir tipos corretos\n",
    "df['Preço'] = pd.to_numeric(df['Preço'], errors='coerce')\n",
    "df['Avaliação_Numérica'] = pd.to_numeric(df['Avaliação_Numérica'], errors='coerce')\n",
    "\n",
    "# --- 2. Filtragem de registros válidos ---\n",
    "# Remover livros sem preço ou avaliação\n",
    "df_filtrado = df.dropna(subset=['Preço', 'Avaliação_Numérica'])\n",
    "df_filtrado = df_filtrado[df_filtrado['Preço'] > 0]\n",
    "\n",
    "print(f\"\\nTotal de livros válidos para análise: {len(df_filtrado)}\")\n",
    "\n",
    "# --- 3. Cálculo de métricas (baseado nas categorias da Parte 2) ---\n",
    "# Estatísticas básicas\n",
    "estatisticas = {\n",
    "    'Média de Preço (R$)': round(df_filtrado['Preço'].mean(), 2),\n",
    "    'Mediana de Preço (R$)': round(df_filtrado['Preço'].median(), 2),\n",
    "    'Média de Avaliação (1-5)': round(df_filtrado['Avaliação_Numérica'].mean(), 1),\n",
    "    'Livros por Categoria de Preço': df_filtrado['Categoria_Preço'].value_counts().to_dict(),\n",
    "    'Livros por Nível de Avaliação': df_filtrado['Avaliação_Categoria'].value_counts().to_dict()\n",
    "}\n",
    "\n",
    "# --- 4. Análise de Relação Preço x Avaliação ---\n",
    "# Agrupar por categoria de preço e avaliação\n",
    "analise_cruzada = pd.crosstab(\n",
    "    df_filtrado['Categoria_Preço'],\n",
    "    df_filtrado['Avaliação_Categoria'],\n",
    "    margins=True\n",
    ")\n",
    "\n",
    "# --- 5. Salvar dados tratados para análise ---\n",
    "df_filtrado.to_csv('dados_finais_para_analise.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# --- 6. Resultados Finais ---\n",
    "print(\"\\n=== Estatísticas Finais ===\")\n",
    "for chave, valor in estatisticas.items():\n",
    "    print(f\"{chave}: {valor}\")\n",
    "\n",
    "print(\"\\nDistribuição Cruzada (Preço x Avaliação):\")\n",
    "print(analise_cruzada)\n",
    "\n",
    "print(\"\\nAmostra dos Dados Finais:\")\n",
    "print(df_filtrado.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 4: Análise e Reflexão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório corrigido gerado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "def gerar_relatorio_final_corrigido():\n",
    "    \"\"\"\n",
    "    Gera relatório final com valores corrigidos conforme saída da Parte 3\n",
    "    \"\"\"\n",
    "    # Dados reais obtidos na etapa 3\n",
    "    dados = {\n",
    "        'total_livros': 60,\n",
    "        'livros_validos': 60,\n",
    "        'preco_medio': 35.0,\n",
    "        'preco_mediano': 33.48,\n",
    "        'avaliacao_media': 3.0,\n",
    "        'distribuicao_precos': {\n",
    "            'Muito Caro': 35,\n",
    "            'Caro': 22,\n",
    "            'Médio': 3,\n",
    "            'Barato': 0\n",
    "        },\n",
    "        'distribuicao_avaliacoes': {\n",
    "            'Bom': 23,\n",
    "            'Ruim': 23,\n",
    "            'Excelente': 14\n",
    "        },\n",
    "        'relacao_preco_avaliacao': {\n",
    "            'Caro': {'Bom': 7, 'Excelente': 7, 'Ruim': 8},\n",
    "            'Muito Caro': {'Bom': 15, 'Excelente': 7, 'Ruim': 13},\n",
    "            'Médio': {'Bom': 1, 'Excelente': 0, 'Ruim': 2}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    relatorio = f\"\"\"\n",
    "# RELATÓRIO FINAL - ANÁLISE DE DADOS DE LIVROS\n",
    "\n",
    "**Data:** {datetime.now().strftime('%d/%m/%Y %H:%M')}\n",
    "**Fonte dos dados:** books.toscrape.com\n",
    "**Total de livros analisados:** {dados['total_livros']}\n",
    "\n",
    "## 1. METRADOS PRINCIPAIS\n",
    "\n",
    "### Preços (em GBP):\n",
    "- **Média:** £{dados['preco_medio']:.2f}\n",
    "- **Mediana:** £{dados['preco_mediano']:.2f}\n",
    "\n",
    "### Avaliações (1-5 estrelas):\n",
    "- **Média:** {dados['avaliacao_media']:.1f}/5.0\n",
    "\n",
    "## 2. DISTRIBUIÇÕES\n",
    "\n",
    "### Categorias de Preço:\n",
    "{formatar_distribuicao(dados['distribuicao_precos'])}\n",
    "\n",
    "### Níveis de Avaliação:\n",
    "{formatar_distribuicao(dados['distribuicao_avaliacoes'])}\n",
    "\n",
    "## 3. RELAÇÃO PREÇO × AVALIAÇÃO\n",
    "\n",
    "{formatar_relacao_preco_avaliacao(dados['relacao_preco_avaliacao'])}\n",
    "\n",
    "## 4. OBSERVAÇÕES IMPORTANTES\n",
    "\n",
    "1. **Distribuição de preços:** \n",
    "   - 58% dos livros estão na categoria \"Muito Caro\"\n",
    "   - Apenas 5% na categoria \"Médio\"\n",
    "\n",
    "2. **Avaliações equilibradas:**\n",
    "   - Distribuição quase igual entre \"Bom\" e \"Ruim\"\n",
    "   - 23% com avaliação \"Excelente\"\n",
    "\n",
    "3. **Relação preço-avaliação:**\n",
    "   - Livros \"Muito Caros\" têm maior variação de avaliações\n",
    "   - Categoria \"Caro\" apresenta melhor equilíbrio qualidade-preço\n",
    "\"\"\"\n",
    "\n",
    "    # Salvar relatório\n",
    "    with open('relatorio_final_corrigido.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(relatorio)\n",
    "\n",
    "    print(\"Relatório corrigido gerado com sucesso!\")\n",
    "\n",
    "# Funções auxiliares atualizadas\n",
    "def formatar_distribuicao(dados):\n",
    "    \"\"\"Formata dados de distribuição com porcentagens\"\"\"\n",
    "    total = sum(dados.values())\n",
    "    return \"\\n\".join(\n",
    "        f\"- {k}: {v} livros ({v/total:.1%})\"\n",
    "        for k, v in dados.items()\n",
    "    )\n",
    "\n",
    "def formatar_relacao_preco_avaliacao(dados):\n",
    "    \"\"\"Formata a tabela de relação preço×avaliação\"\"\"\n",
    "    tabela = []\n",
    "    for categoria, avaliacoes in dados.items():\n",
    "        total = sum(avaliacoes.values())\n",
    "        linha = [f\"**{categoria}**\"]\n",
    "        linha.extend(f\"{k}: {v} ({v/total:.1%})\" for k, v in avaliacoes.items())\n",
    "        tabela.append(\" | \".join(linha))\n",
    "    \n",
    "    header = \"| Categoria | Bom | Excelente | Ruim |\\n|-----------|-----|-----------|------|\"\n",
    "    return header + \"\\n\" + \"\\n\".join(f\"| {linha} |\" for linha in tabela)\n",
    "\n",
    "# Executar\n",
    "if __name__ == \"__main__\":\n",
    "    gerar_relatorio_final_corrigido()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".estudos_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
